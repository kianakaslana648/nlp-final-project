<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="">
  <title>An Interesting & Dramatic Chatbot</title>

  <!-- CSS only -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.0/dist/css/bootstrap.min.css" rel="stylesheet"
    integrity="sha384-gH2yIJqKdNHPEq0n4Mqa/HGKIhSkIHeL5AyhkYV8i59U5AR6csBvApHHNl/vI1Bx" crossorigin="anonymous">
  <link href="/docs/5.2/dist/css/bootstrap.min.css" rel="stylesheet"
    integrity="sha384-gH2yIJqKdNHPEq0n4Mqa/HGKIhSkIHeL5AyhkYV8i59U5AR6csBvApHHNl/vI1Bx" crossorigin="anonymous">

  <!-- Favicons -->

  <!-- Custom styles for this template -->
  <link href="style/styles.css" rel="stylesheet">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>

</head>

<body>

  <!-- Navbar -->
  <div class="container" style="max-width: 800px">

    <h2 style='text-align: center; font-family: "Lucida Handwriting", "Brush Script MT", cursive;'>An Interesting & Dramatic Chatbot</h2>
    <br>
    <p style='font-size: 20px; text-align: right; font-family: "Times New Roman", Times, serif;'>
      Final Project of ANLY580 <br>
      Natural Language Processing <br>
      at Georgetown University</p>
    
    <hr style=" border-top: 8px solid #bbb; border-radius: 5px;">
    Authors: Minglei Cai, Jieqian Liu, Jieyi Sun, Zidong Xu
    <hr style=" border-top: 8px solid #bbb; border-radius: 5px;">
   
    <h4 style='font-family: "Times New Roman", Times, serif;'>
      <strong>An Introduction to Chatbots</strong>
    </h4>
    <div class="row py-5">
    
              <div class="col-md-12">
                <div class="card p-0" style="border: none">
                  <img src="imgs/introduction.png" style="margin:auto;" alt="..." width="500">
                  <div class="card-body">
                    <p style="font-weight: lighter; text-align: center;">How Chatbot Works</p>
    
                  </div>
                </div>
              </div>
    </div>
    <p>
      <strong>Chatbots</strong> 
      generally represent for the software applications which can 
      carry out live conversations with users' utterances in the form of text or audio. 
      While a lot of research has been done on chatbots for the theories and engineering techniques, 
      a number of chatbot applications have been also developed in different settings.
      The chatbots could be divided into different categories according to the usage and principles behind,
      among which some popular ones are:
    </p>
    <ul>
      <li><strong>Customer Service Chatbots:</strong> Carry out Q&As and provide service options
      for the customers. Typical examples are customer service chatbots of e-commerce companies,
      such as <strong>Amazon</strong> and <strong>Ebay</strong>.</li>
      <li><strong>Task Oriented Chatbots:</strong> Answer questions and have the ability to
        complete specific tasks, such as scheduling appointments and making calls. 
        Two typical examples are <strong>Siri</strong> from <strong>Apple</strong> and 
        <strong>Cortana</strong> from <strong>Microsoft</strong>.</li>
      <li><strong>Open Domain Chatbots:</strong> Chat with users in turns in an open domain, not 
      restricted to specific tasks, sometimes within certain topics. </li>
    </ul>
    <br>
    <hr>
    <h4 style='font-family: "Times New Roman", Times, serif;'>
      <strong>Project Goals</strong>
    </h4>
    <br>
    <p>
      For our project, we place our interests and efforts on the open-domain chatbots.
      We expect to build an open-domain chatbot with dramatic responses,
      which has the ability of 'chatting' with the user in an interesting and interactive way.

    </p>
    <p>
      Our basic idea is first load the open-source pre-trained models of <strong>DialoGPT</strong>,
      which are from microsoft and trained primarily on twits and reddits.
      Then we finetune the model on the movie dialogue corpus, 
      in the assumption that conversations in movies tend to be more dramatic and 
      emotional, different from common conversations with more apparent features that is easy for us to build models, specifically tweets and reddits. 
      We finally deploy the chatbots using google voice API. More technical details are provided in the
      following parts.
    </p>
    <p>
      Our business goal is to give the user a surprise, a sense of happiness, 
      and a relief temporarily from the heavy everyday work and studies.
    </p>
    <br>
    <hr>

    <h4 style='font-family: "Times New Roman", Times, serif;'>
      <strong>Pre-trained Model</strong>
    </h4>
    <br>
            <p><strong>DialoGPT</strong> from <strong>microsoft</strong></p>
            <p> Model link from <strong>huggingface</strong>: <a href="https://huggingface.co/microsoft/DialoGPT-medium">microsoft/DialoGPT</a></p>
            <ul>
            <p>
             The DialoGPT was released by Microsoft and trained with 147M multi-turn dialogues extracted from Reddit discussion threads. It has strong flexibility and robustness. As an autoregressive (AR) language model which uses a multi-layer transformer as its model architecture, it establishes a foundation for building versatile open-domain chatbots which can deliver engaging and natural conversational responses across various topics, tasks, and information requests, without resorting to heavy hand-crafting.
            </p>
              
            <p>
              According to the human evaluation results, the response generated from DialoGPT is comparable to human response quality under a single-turn conversation Turing test.
            </P>
     
            <div class="row py-5">
    
              <div class="col-md-12">
                <div class="card p-0" style="border: none">
                  <img src="imgs/pretrain_model_evaluation.png" style="margin:auto;" alt="..." width="500">
      
                </div>
              </div>
             </div>
            </ul>
    <br>
    <hr>
    <h4 style='font-family: "Times New Roman", Times, serif;'>
      <strong>DataSet</strong>
    </h4>
        <br>
           <p>
              <strong>Dataset overview:</strong>
          </p>
     
            <div class="row py-5">
              <div class="col-md-12">
                <div class="card p-0" style="border: none">
                  <img src="imgs/dataset_overview.png" style="margin:auto;" alt="..." width="700">
      
                </div>
              </div>
             </div>
  
            <p>
              The <strong>Movie Dialogue Corpus</strong> contains a metadata-rich collection of fictional conversations extracted from raw movie scripts:
               <a href="https://www.kaggle.com/datasets/Cornell-University/movie-dialog-corpus">movie-dialog-corpus-kaggle-link</a>
            </p>
           
            
            <p>
            This dataset only includes movies that had more than 5 IMDB (The Internet Movie Database; data interfaces available at http://www.imdb.com/interfaces) votes, which includes 220,579 conversational exchanges between 10,292 pairs of movie characters, 9,035 characters from 617 movies, and a totally of 304,713 utterances.
            </P>
  
            <br>
            <p>
              <strong>Data Cleaning</strong>
            </p>
            <p>
                First, we joined tables and got all the conversations in movies tagged by ‘comedy’, and then we use Regular expressions to remove unnecessary symbols from the actual text of each utterance we extracted before.
            </P>
            <p>
                What's more, we found that there are too many repeated sentences like ‘Yes’, ‘No’, ‘I don’t know’, ‘I’m sorry’ in our training data sets. 
                To avoid the situation the chatbot respond too many such words to users instead of humorous responses, 
                we removed these superfluous words from our training dataset. 
            </P>
            <p>
                In experiments of interacting with this chatbot, we found that it tends to give very short response. 
                Since the business goal of this chatbot is to help users to pass the time away and gives users entertainment, 
                such short conversations are not wanted by users. Therefore, we filtered out all sentences with length under 10.
            </P>
    
    <br>
    <hr>
 

    <h4 style='font-family: "Times New Roman", Times, serif;'>
      <strong>Fine-tuning</strong>
    </h4>
        <br>
            <p>
              <strong>Hardware Support for Training:</strong>
            </p>
            <ul>
              <li>
                To adjust the chatbot precisely so as to bring to the highest level of performance and effective, 
                the hardware support we chose for training is Colab Pro+ with 800 compute units which cost us $80 per month. 
              </li>
              <li>
                To ensure that we have enough cloud storage, we used Google One with 100 GB storage which cost us $2 per month.  
              </li>
              <li>
                We used benchmarks of Intel Core i7-10750H with RAM 16GB which is one of the fastest laptop processors on the market. 
              </li>
            </ul>
            <br>
            <p>
              <strong>Finetuning Time:</strong>(Epochs:2 Batch_size:4)
            </p>
            <p>
                DialoGPT is a SOTA large-scale pretrained dialogue response generation model for nultiturn conversations. 
                In the human evaluation, we have used three DialoGPT with different size and compare the time of response generated from DialoGPT. 
              
            <p>
                We waited around 35 minutes for DialoGPT-small (0.5 GB) to respond, 
                80 minutes for DialoGPT-medium (1.4 GB) to respond, 135 minutes for DialoGPT-large (2.9 GB) to respond.
            
            <br>
            <p>
              <strong>Training Loss Visualization:</strong>(Screenshots of Tensorboard)
            </p>
            <table>
              <tr>
                <td>
                  <!-- IMAGE: body length comparison -->
                  <div class="row py-5">
          
                    <div class="col-md-12">
                      <div class="card p-0" style="border: none">
                        <img src="imgs/loss-small.jpg" class="card-img-top" alt="...">
                        <div class="card-body">
                          <p style="font-weight: lighter; text-align: center;">Loss Record of Small-Size Model Finetuning</p>
          
                        </div>
                      </div>
                    </div>
                  </div>
                  <!-- IMAGE END -->
                </td>
                <td>
                  <!-- IMAGE: body length comparison -->
                  <div class="row py-5">
          
                    <div class="col-md-12">
                      <div class="card p-0" style="border: none">
                        <img src="imgs/loss-large.jpg" class="card-img-top" alt="...">
                        <div class="card-body">
                          <p style="font-weight: lighter; text-align: center;">Loss Record of Large-Size Model Finetuning</p>
          
                        </div>
                      </div>
                    </div>
                  </div>
                  <!-- IMAGE END -->
                </td>
              </tr>                  
            </table>
            <!-- IMAGE: body length comparison -->
                  <div class="row py-5">
          
                    <div class="col-md-12">
                      <div class="card p-0" style="border: none">
                        <img src="imgs/loss-medium.jpg" class="card-img-top" alt="...">
                        <div class="card-body">
                          <p style="font-weight: lighter; text-align: center;">Loss Record of Medium-Size Model Finetuning</p>
          
                        </div>
                      </div>
                    </div>
                  </div>
                  <!-- IMAGE END -->
                  
              
            <!-- IMAGE END -->      
            <ul>
              <li>
                We use the training loss as part of our standards for the hyper-parameter selection.
              </li>
              <li>
                We have trials of the small-size models to find a roughly appropriate range
                for the learning rate. We also test the trick of clipping gradient norms in this
                setting. According to the loss, it's better to clip the gradients.
              </li>
              <li>
                We give only one trial to the large-size model, considering the time and cost.
              </li>
              <li>
                We place our focus on the medium-size models. According to the loss plot, we
                can see that 2 epochs is enough. From these finetuning processes, we get different
                examples of models, which could be deployed later.
              </li>
            </ul>
    <br>
    <hr>


    <h4 style='font-family: "Times New Roman", Times, serif;'>
      <strong>Deploy</strong>
    </h4>
    <br>
            <p>
                We used Google Voice API to receive messages, autosave messages to gmail. 
                Then processed unread messages every 5 seconds, using our models. 
                Finally sent processed messages through our virtual number (+1 2028884948). 
                All messages were processed in different sessions which are classified by sender numbers.
            </P>
            <p>
                Since there were no extra machines nor rent any servers, 
                we deployed our models just on Google Colab. 
                Considering the price of google colab, it is not 24-hour deployed, only running when we want to make interactions with our chatbot.
            </P>          
    <br>
    <hr>

    <h4 style='font-family: "Times New Roman", Times, serif;'>
      <strong>Demo</strong>
    </h4>
    <br>
    <p>Let's see a demo first.</p>
    <div class="row py-5">
    
      <div class="col-md-12">
        <div class="card p-0" style="border: none">
          <video width="250" style="margin:auto;" controls >
            <source src="demos/demo1.mp4"  type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <div class="card-body">
            <p style="font-weight: lighter; text-align: center;">An Interesting Demo</p>

          </div>
        </div>
      </div>
    </div>
    <p>Going through a testing phrase before releasing our chat robot is quite important. 
      We must keep on monitoring results even after going live. 
      We have performed many experiments using models of different size and training data sets. 
      Finally, we got a satisfying chatbot whose name is SweetHeart. 
      SweetHeart was implemented with DialoGPT-medium and the dataset after cleaning.</p>

    <br>
    <hr>
    <h4 style='font-family: "Times New Roman", Times, serif;'>
      <strong>More Interactions</strong>
    </h4>
    <br>
    <p>After improving the data-cleaning process and finetuning process and having more trails for the hyper-parameters, 
      our SweetHeart became more humorous and interactive. Here are more interesting interaction with our SweetHeart.:</p>

    <table style="margin:auto;">
      <tr>
        <td>
          <div class="row py-5">
            <div class="col-md-12">
              <div class="card p-0" style="border: none">
                <img src="imgs/Screenshot1.jpg" width='200px' style="margin:auto;" alt="...">
              </div>
            </div>
          </div>
        </td>

        <td>
          <div class="row py-5">
            <div class="col-md-12">
              <div class="card p-0" style="border: none">
                <img src="imgs/Screenshot2.jpg" width='200px' style="margin:auto;" alt="...">
              </div>
            </div>
          </div>
        </td>
      </tr>
      <tr>
        <td>
          <div class="row py-5">
            <div class="col-md-12">
              <div class="card p-0" style="border: none">
                <img src="imgs/Screenshot3.jpg" width='200px' style="margin:auto;" alt="..." >
              </div>
            </div>
          </div>
        </td>
        <td>
          <div class="row py-5">
            <div class="col-md-12">
              <div class="card p-0" style="border: none">
                <img src="imgs/Screenshot4.jpg" width='200px' style="margin:auto;" alt="..." >
              </div>
            </div>
          </div>
        </td>
      </tr>
    </table>
    <div class="card-body">
      <p style="font-weight: lighter; text-align: center;">Screenshots of More Interesting Interactions</p>

    </div>
    <br>
    <p>
      We interacted with our SweetHeart using common sentences, philosophical questions, quotes of Darks Souls & 
      Elden Ring, poems by Load Byron. And in reply our SweetHeart presented us with some surprises!
    </p>
    <p>
      While original DialoGPT tends to give longer replies as illustrations to the question 
      'What's the meaning of Life?', this chatbot tends to reply in a short and smarter way, which 
      is expected in movie conversations.
    </p>
    <br>
    <hr>


    <h4 style='font-family: "Times New Roman", Times, serif;'>
      <strong>Conclusions</strong>
    </h4>
    <br>
    <p>
      Above is all about our NLP final project regarding building a chatbot. 
      Although our SweetHeart chatbot interacts with us as what we've expected, 
      more complex structures and more advanced techniques can be applied to our chatbot in the future.
    </p>
    <p>
      There is a famous and instructive quote from <strong>Dr. Seuss</strong>:
    </p>
    <p style="font-family: cursive;">
       The more that you read, the more things you will know.<br>
        The more that you learn, the more places you’ll go.
    </p>
    <p>
      While our chatbot has learned from the movie conversations, 
      it is expected that it can learn from daily conversations which have less features and interacted as real. 
      We ourselves also need to keep learning from more papers and applications, 
      in the hope to improve our lovely chatbot and build more interesting and elegant models in the future.
    </p>
    <br>
    <hr>

    <h4 style='font-family: "Times New Roman", Times, serif;'>
      <strong>Future Work</strong>
    </h4>
    <br>
    <p> 
      There are still some goals we need to achieve in the future to improve the performance of our model. 
      For the method we used this time, it simply shuffles the training dataset. 
      It may perform much better if we try state-of-the-art planning strategies. 
      Also, if we finetune on larger datasets that balanced and explicitly in some certain utterance style, 
      the quality of reply of our chatbot can be higher. 
      The reply from our model contains a lots of adversarial or meaningless sentences. 
      So we need to find a solution to filter those unwanted replies.</p>
    <br>
    <hr>

        <h4 style='font-family: "Times New Roman", Times, serif;'>
      <strong>Links</strong>
    </h4>
            <br>
            <ul>
              <li>
                <a href="https://github.com/kianakaslana648/nlp-final-project">Github Repo</a> for tutorial of data cleaning,
            finetuning and deploying.
              </li>
              <li>
                <a href="https://huggingface.co/Kiana648/movie_dialogue_gpt2">Huggingface Page</a> for the finetuned model(in medium size).
              </li>
            </ul>
    <br>
    <hr>

    <h4 style='font-family: "Times New Roman", Times, serif;'>
      <strong>References</strong>
    </h4>
           <ul>
              <li>
                <a href="https://www.microsoft.com/en-us/research/project/large-scale-pretraining-for-response-generation/">DialoGPT: Toward Human-Quality Conversational Response Generation via Large-Scale Pretraining</a> 
              </li>
              <li>
                <a href="https://aclanthology.org/2020.acl-demos.30.pdf">DIALOGPT : Large-Scale Generative Pre-training for Conversational Response Generation</a> 
              </li>
            </ul>     
   
    
  </div> <!-- container -->
  <footer class="blog-footer">
    <p>
      <a href="#">Back to top</a>
    </p>
  </footer>

</body>

</html>
